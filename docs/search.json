[
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hey there, I'm Lukas ðŸ‘‹",
    "section": "",
    "text": "Hey there, I'm Lukas ðŸ‘‹\n\n  \n \n \n  \n   \n  \n    \n     Twitter\n  \n  \n    \n     Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n\n\n\nWelcome to my corner of the internet! Iâ€™m a PhD student shared between the Department of Biosystems Science and Engineering at ETH and the Roche Institute of Human Biology (IHB) in Basel. For my PhD, I aim to resolve how gene regulatory networks are wired in the intestine and which components are truly unique to humans. To bring these mysteries to light, Iâ€™m using single-cell multi-omics, perturbation & comparative genomics data.\nBeyond research, Iâ€™m passionate about coding, data exploration, and sharing knowledge. This blog is my way of combining those interests â€” an evolving space to teach and learn about all things data analysis, from biology to the broader world.\nThanks for stopping by and letâ€™s explore data related concepts together! ðŸš€\n\n\n\n\nHere are my latest blog posts\n\n\n\n\n\n\n\n\n\n\nHow to handle a very special snowflake\n\n\n\n\n\n\n\n\n\nDec 23, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-12-23-A-special-snowflake/01_Handling_the_Snowflake.html",
    "href": "posts/2024-12-23-A-special-snowflake/01_Handling_the_Snowflake.html",
    "title": "How to handle a very special snowflake",
    "section": "",
    "text": "Snowflakeâ€™s design philosophyâ€”decoupling compute and storage, supporting multi-cloud environments, and enabling seamless scalabilityâ€”sets it apart from traditional data warehouses. Add in features like zero-copy cloning, seamless handling of semi-structured data, and real-time data sharing, and you have a platform thatâ€™s not only efficient but also innovative. So, next time someone asks you why Snowflake is so special, youâ€™ll know exactly what to say. Alright, alrightâ€¦but how do we actually handle the snowflake (upload/download files) using our favorite programming languange python? This is what I will show you today using a simple wrapper class."
  },
  {
    "objectID": "posts/2024-12-23-A-special-snowflake/01_Handling_the_Snowflake.html#what-is-snowflake",
    "href": "posts/2024-12-23-A-special-snowflake/01_Handling_the_Snowflake.html#what-is-snowflake",
    "title": "How to handle a very special snowflake",
    "section": "What Is Snowflake?",
    "text": "What Is Snowflake?\nSnowflake is a cloud-native data platform that provides a fully managed service for data warehousing, data lakes, and data analytics. Unlike traditional data warehouses, which often require heavy infrastructure management and scaling considerations, Snowflake was built from the ground up to leverage the power and flexibility of the cloud.\nBut what exactly makes Snowflake so special? Letâ€™s break it down."
  },
  {
    "objectID": "posts/2024-12-23-A-special-snowflake/01_Handling_the_Snowflake.html#handle-the-snowflake-from-python",
    "href": "posts/2024-12-23-A-special-snowflake/01_Handling_the_Snowflake.html#handle-the-snowflake-from-python",
    "title": "How to handle a very special snowflake",
    "section": "Handle the snowflake from python",
    "text": "Handle the snowflake from python\n\nimport os\nimport json\nimport pandas as pd\nimport snowflake.connector\n\nclass SnowflakeHandler:\n    \"\"\"\n    A wrapper class to upload local CSV files to a Snowflake stage, load the data into a table,\n    and download data from a Snowflake table to a local file.\n    \"\"\"\n    def __init__(self, local_file_path=None, table_name=None, stage_name=\"@~\", config_path=\"config.json\"):\n        \"\"\"\n        Initialize the SnowflakeHandler with file paths, table name, and connection details.\n        \n        Args:\n            local_file_path (str): Local path to the CSV file for upload/download.\n            table_name (str): Target Snowflake table name.\n            stage_name (str): Snowflake stage name. Defaults to '@~'.\n            config_path (str): Path to the JSON configuration file with Snowflake credentials.\n        \"\"\"\n        self.local_file_path = local_file_path\n        self.table_name = table_name\n        self.stage_name = stage_name\n        self.snowflake_stage_file = os.path.basename(local_file_path) if local_file_path else None\n        \n        # Load Snowflake connection parameters from the config file\n        with open(config_path, 'r') as f:\n            self.conn_params = json.load(f)\n        \n        # Connect to Snowflake\n        self.conn = snowflake.connector.connect(**self.conn_params)\n        self.cur = self.conn.cursor()\n\n    def map_dtype_to_snowflake(self, dtype):\n        \"\"\"\n        Map pandas data types to Snowflake SQL types.\n        \n        Args:\n            dtype (dtype): Pandas data type.\n        \n        Returns:\n            str: Corresponding Snowflake SQL type.\n        \"\"\"\n        if pd.api.types.is_integer_dtype(dtype):\n            return \"INTEGER\"\n        elif pd.api.types.is_float_dtype(dtype):\n            return \"FLOAT\"\n        elif pd.api.types.is_bool_dtype(dtype):\n            return \"BOOLEAN\"\n        elif pd.api.types.is_datetime64_any_dtype(dtype):\n            return \"TIMESTAMP\"\n        else:\n            return \"STRING\"\n\n    def generate_create_table_command(self, df):\n        \"\"\"\n        Generate a CREATE TABLE SQL statement based on a DataFrame's schema.\n        \n        Args:\n            df (pd.DataFrame): DataFrame for inferring table schema.\n        \n        Returns:\n            str: SQL command to create the table.\n        \"\"\"\n        column_definitions = []\n        for col in df.columns:\n            col_type = self.map_dtype_to_snowflake(df[col].dtype)\n            column_definitions.append(f'\"{col}\" {col_type}')\n        column_definitions_str = \",\\n    \".join(column_definitions)\n        \n        return f\"\"\"\n        CREATE OR REPLACE TABLE {self.table_name} (\n            {column_definitions_str}\n        );\n        \"\"\"\n\n    def upload_file_to_stage(self):\n        \"\"\"\n        Upload the local CSV file to the Snowflake stage.\n        \"\"\"\n        put_command = f\"PUT 'file://{self.local_file_path}' {self.stage_name}/{self.snowflake_stage_file} AUTO_COMPRESS=FALSE\"\n        self.cur.execute(put_command)\n        print(f\"File '{self.snowflake_stage_file}' uploaded to Snowflake stage '{self.stage_name}'.\")\n\n    def load_data_into_table(self):\n        \"\"\"\n        Copy the staged file into the Snowflake table.\n        \"\"\"\n        copy_command = f\"\"\"\n        COPY INTO {self.table_name}\n        FROM {self.stage_name}/{self.snowflake_stage_file}\n        FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '\"' SKIP_HEADER = 1)\n        \"\"\"\n        self.cur.execute(copy_command)\n        print(f\"Data from '{self.snowflake_stage_file}' successfully loaded into table '{self.table_name}'.\")\n\n    def download_table(self):\n        \"\"\"\n        Download data from a Snowflake table and save it as a local CSV file.\n        \"\"\"\n        query = f\"SELECT * FROM {self.table_name}\"\n        self.cur.execute(query)\n        \n        # Fetch all rows and column names\n        data = self.cur.fetchall()\n        column_names = [desc[0] for desc in self.cur.description]\n        \n        # Save to CSV using pandas\n        df = pd.DataFrame(data, columns=column_names)\n        df.to_csv(self.local_file_path, index=False)\n        print(f\"Data from table '{self.table_name}' successfully downloaded to '{self.local_file_path}'.\")\n\n    def upload_table(self):\n        \"\"\"\n        Full process: Upload file, generate table schema, create table, and load data.\n        \"\"\"\n        # Read the CSV file to infer schema\n        df = pd.read_csv(self.local_file_path)\n        \n        # Step 1: Upload file to stage\n        self.upload_file_to_stage()\n        \n        # Step 2: Generate and execute CREATE TABLE command\n        create_table_sql = self.generate_create_table_command(df)\n        self.cur.execute(create_table_sql)\n        print(f\"Table '{self.table_name}' created successfully.\")\n        \n        # Step 3: Load data into table\n        self.load_data_into_table()\n\n    def close_connection(self):\n        \"\"\"\n        Close the Snowflake connection.\n        \"\"\"\n        self.cur.close()\n        self.conn.close()\n        print(\"Snowflake connection closed.\")\n\nNow we can upload or download data from the snowflake however we want. Bear in mind that we currently only support upload of csv files. Similarly, downloading tables from the cloud will save them as csv files. Given that we can also upload semi-structured data, Iâ€™d like to see whether we can also upload parquet or feather files, which would drastically enhance the usability.\n\n# Parameters for file upload\nlocal_csv_path = \"/Users/adaml9/Private/kaggle/playground-series/s4e11/train.csv\" \nconfig_path = \"/Users/adaml9/Private/snowflake/upload/config.json\"\nstage_name = \"@~\"\ntable_name = \"TRAIN\"\n\n# Initialize and execute\nhandler = SnowflakeHandler(\n        local_file_path=local_csv_path,\n        table_name=table_name,\n        stage_name=stage_name,\n        config_path=config_path\n    )\nhandler.upload_table()\nhandler.close_connection()\n\n\n# Parameters for file upload\nlocal_csv_path = \"/Users/adaml9/Private/kaggle/playground-series/s4e11/train2.csv\" \nconfig_path = \"/Users/adaml9/Private/snowflake/upload/config.json\"\nstage_name = \"@~\"\ntable_name = \"TRAIN\"\n\n# Initialize and execute\nhandler = SnowflakeHandler(\n        local_file_path=local_csv_path,\n        table_name=table_name,\n        stage_name=stage_name,\n        config_path=config_path\n    )\nhandler.download_table()\nhandler.close_connection()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]